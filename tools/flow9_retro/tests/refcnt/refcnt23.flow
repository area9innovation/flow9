native println2 : io (flow) -> void = Native.println;

Struct1(s : string);


// ------------------------------------------------------------------------------------------
fn1(v : string) -> void {
	{}
}
foo1() -> void {
	fn1("foo1");
}
// ------------------------------------------------------------------------------------------
fn2() -> string {
	"foo2"
}
foo2() -> void {
	fn2();
	{}
}
// ------------------------------------------------------------------------------------------
foo3() -> void {
	v = Struct1("foo3");
	b = v.s;
	{}
}
// ------------------------------------------------------------------------------------------
foo4() -> void {
	v = Struct1("foo3");
	b = v.s;
	v;
	{}
}
// ------------------------------------------------------------------------------------------
fn5() -> string {
	"Compared to a generational tracing collector, reference counting has low memory overhead and is straightforward to implement. However, while the cost of tracing collectors is linear in the live data, the cost of reference counting is linear in the number of reference counting operations. Optimizing the total cost of reference counting operations is therefore our main priority. There are at least three known problems that make reference counting operations expensive in practice and generally inferior to tracing collectors:
- Concurrency: when multiple threads share a data structure, reference count operations need to be atomic, which is expensive.
- Precision: common reference counted systems are not precise and hold on to objects too long. This increases memory usage and prevents aggressive optimization of many reference count operations.
- Cycles: if object references form a cycle, the runtime needs to handle them separately, which re-introduces many of the drawbacks of a tracing collector.
We handle each of these issues in the context of an eager, functional language using immutable data types together with a strong type and effect system. For concurrency, we precisely track when objects can become thread-shared (Section 2.7.2). For precision, we introduce Perceus, our algorithm for inserting precise reference counting operations that can be aggressively optimized. In particular, we eliminate and fuse many reference count operations with drop specialization (Section 2.3), turn functional matching into in-place updates with reuse analysis (Section 2.4), and minimize field updates with reuse specialization (Section 2.5). Finally, although we currently do not supply a cycle collector, our design has two important mitigations. First, (co)inductive data types and eager evaluation prevent cycles outside of explicit mutable references, and it is statically known where cycles can possibly be introduced in the code (Section 2.7.4). Second, being a mostly functional language, mutable references are not often used, and on top of that, reuse analysis greatly reduces the need for them since in-place mutation is typically inferred. The reference count optimizations are our main contribution and we start with a detailed overview in the following sections, ending with details about";
}
foo5() -> void {
	v = Struct1(fn5());
	arr = [v, v];
	{}
}
// ------------------------------------------------------------------------------------------
foo6() -> void {
	v = Struct1("foo3");
	b = v.s;
	b;
	{}
}
// ------------------------------------------------------------------------------------------
foo7() -> void {
	s = "foo7";
	ns = "fn " + s;
	s;
	ns;
	{}
}
// ------------------------------------------------------------------------------------------
foo8() -> void {
	s = "foo7";
	ns = s + "fn ";
	s;
	{}
}
// ------------------------------------------------------------------------------------------
foo9() -> void {
	s = "foo7";
	ns = "fn " + s;
	{}
}
// ------------------------------------------------------------------------------------------
foo10() -> void {
	"foo" + "10";
	{}
}
// ------------------------------------------------------------------------------------------
foo11() -> void {
	v = Struct1("Compared to a generational tracing collector, reference counting has low memory overhead and is straightforward to implement. However, while the cost of tracing collectors is linear in the live data, the cost of reference counting is linear in the number of reference counting operations. Optimizing the total cost of reference counting operations is therefore our main priority. There are at least three known problems that make reference counting operations expensive in practice and generally inferior to tracing collectors:
- Concurrency: when multiple threads share a data structure, reference count operations need to be atomic, which is expensive.
- Precision: common reference counted systems are not precise and hold on to objects too long. This increases memory usage and prevents aggressive optimization of many reference count operations.
- Cycles: if object references form a cycle, the runtime needs to handle them separately, which re-introduces many of the drawbacks of a tracing collector.
We handle each of these issues in the context of an eager, functional language using immutable data types together with a strong type and effect system. For concurrency, we precisely track when objects can become thread-shared (Section 2.7.2). For precision, we introduce Perceus, our algorithm for inserting precise reference counting operations that can be aggressively optimized. In particular, we eliminate and fuse many reference count operations with drop specialization (Section 2.3), turn functional matching into in-place updates with reuse analysis (Section 2.4), and minimize field updates with reuse specialization (Section 2.5). Finally, although we currently do not supply a cycle collector, our design has two important mitigations. First, (co)inductive data types and eager evaluation prevent cycles outside of explicit mutable references, and it is statically known where cycles can possibly be introduced in the code (Section 2.7.4). Second, being a mostly functional language, mutable references are not often used, and on top of that, reuse analysis greatly reduces the need for them since in-place mutation is typically inferred. The reference count optimizations are our main contribution and we start with a detailed overview in the following sections, ending with details about");
	a = v.s;
	b = v.s;
}
// ------------------------------------------------------------------------------------------
foo12() -> void {
	"foo";
	{}
}
// ------------------------------------------------------------------------------------------


// ------------------------------------------------------------------------------------------
main() {
	foo1();
	foo2();
	foo3();
	foo4();
	foo5();
	foo6();
	foo7();
	foo8();
	foo9();
	foo10();
	foo11();
	foo12();
	{}
}
